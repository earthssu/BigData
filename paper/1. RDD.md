# RDD
- Resilient Distributed Datasets : 탄력적인 분산 데이터 집합
- Fault-Tolerant and In memory structure

### 1. Motivation
- 기존의 MapReduce와 Dryad는 데이터 분석을 용이하게 만들었다.
- 하지만, 반복 알고리즘, 대화형 데이터 분석에서 매우 비효율적이였다.
- MapReduce에 제한된 방식들은 Fault-Tolerant와 성능 사이에서 trade-off를 선택해야 했다.

### 2. RDD
- spark의 RDD는 MapReduce의 장점을 유지하면서 중간 결과값을 효율적으로 재사용하는 것을 목표로 한다.
- Fault-Tolerance를 유지하는 것이 가장 큰 Challenge이다.
  - 일반적인 Fault-Tolerance 구현법은 Checkpointing과 Logging up update이다.
    - MapReduce는 Checkpointing을 이용하는 방식으로 DiskIO overhead가 발생한다.
    - RDD는 Logging up update를 사용한다. 이 또한, memory 용량을 넘어가면, DiskIO를 피할 수 없다.
    - 따라서, RDD는 중간 결과값을 생성할 수 있는 작업 목록을 저장한다.
    - 이를 통해 장애가 발생했을 때, 작업 목록을 통해서 중간 결과값을 다시 생성해낸다.
- lazy scheduling을 통해 모든 작업은 실제로 결과를 생성할 때, 모든 것이 sheduling되어 사용된다. <br>
이를 통해 pipelining을 이용하기 매우 용이하다.
- 중간 결과를 어떻게 나눌지는 사용자가 직접 정의할 수 있다.

### 3. Spark Interface
- 개발자는 spark를 이용하여 driver program(main문)을 실행한다.
- driver program은 lazy scheduling에 따라서 worker 노드에게 작업이 나뉜다.
- driver는 RDD를 정의하고, Transformation을 통해 원하는 작업을 수행한다.
- 마지막으로, 값의 변환 또는 외부 storage에 데이터를 쓰기 위해 계산을 시작한다.

### 4. RDD Representation
- RDD는 5개의 내부 정보를 포함한다.
  1. Partition : RDD를 나누는 단위.
  2. Dependency : RDD의 각 partition이 어디에서 파생되었는지를 나타냄.
  3. Function : 부모 RDD로 돌아가는 연산 함수(recomputing).
  4. Metadata : RDD의 데이터의 위치와 같은 데이터.
- Dependency
  - Dependency는 두 가지 종료가 있다.
    1. Narrow Dependency: 하나의 partition이 하나의 partition에 mapping되는 경우.
      - recomputing 비용이 적다. 한 번만 뒤로 돌아가면 되기 때문이다.
    2. Wide Dependency: 하나의 partition이 두 개 이상의 partition에 mapping되는 경우.
      - recomputing 비용이 크다. 다른 모든 부모 partition에게 다시 받는 과정이 발생한다.

### 5. Job Scheduling
- 사용자가 RDD에 대해 action을 실행할 때마다 scheduler는 RDD의 lineage 그래프를 검사형 실행할 stage의 DAG(Cycle이 존재하지 않는 Graph)를 작성한다.
- pipelining을 수행하기 위해서 stage를 나누는 단계가 필요하다.
- stage를 나누는 기준은 Wide Dependency의 유무이다.
- Wide Dependency가 발생할 때, 데이터를 재연산하는 비용이 많이 든다는 것을 기반으로 다음 단계로 넘어갈 때는 caching하기 위해서 staging을 나눈다.
- 이러한 복구를 위해 각 stage마다 중간 recoed를 작성해놓는다. (partition을)어디서 불러올것인가에 대한 정보

### 6. RDD Caching
- RDD의 Caching은 3가지 방식이 있다.
  - on-DISK : Disk에 caching하는 방식 비용이 크다.
  - in-Memory : Memory에 caching하는 방식
  - JAVA off-HEAP : on-Disk와 in-Memory의 딱 중간이다.
- serialization : 직렬화를 통해서 데이터를 더 압축할 수 있다.
