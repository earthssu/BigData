# MapReduce Workflow


### MapReduce1

##### BackGround
- client : job을 의뢰한 주체
- jobTracker : job을 조화롭게 관리.
- taskTracker : job을 쪼갠 task를 수행.
- HDFS : Hadoop의 fileSystem.

##### Job Intialization
- Job 수행을 의뢰받으면, job scheduler에 해당 내용을 queue에 넣는다.
- Job scheduler는 하나의 split 당 하나의 map task를 만들어낸다.

##### Task Assignment
- TaskTracker는 map/reduce task를 위한 정해진 숫자의 slot을 갖고 있다.
- Reduce는 아무렇게 할당되어 실행된다.
- 하지만, map작업에서는 network의 locality를 고려하여 설계를 한다.

##### Update
- jobTracker에게 status와 progress를 전송하여 이를 업데이트한다.
- 이를 통해 jobTracker는 전체적인 상태를 파악할 수 있습니다.

### MapReduce2(YARN)
- resource 관리는 resourceManager가 수행하고, <br>
task progress monitoring은 application Master가 수행하며 <br>
scheduling은 scheduler가 수행한다.
- 클러스터의 자원들은 container라는 단위로 표현된다.
- 각 각의 노드안에서 container들은 node manager에 의해서 관리된다.

##### Job Submission
- resourceManager에게 새로운 application ID를 할당해줄 것을 요청.
- 해당 작업의 output의 세부사항을 체크한다.
- input splits를 계산한다.
- 작업을 수행하는데 필요한 자원을 복사한다.(Ex. JAR File, configuration file, input split 등)
- 최종으로 application을 ResourceManager에 전송한다.

##### Job Intialization
- scheduler는 node Manager를 하나 만들고 container를 할당하여 application master를 실행시킨다.
- application Master는 작업을 초기화한다.(이때, task들로 부터 많은 report와 정보를 받을 것이므로 많은 양의 저장 공간을 만들어 낸다.)
- 만약 job의 크기가 작다면, 자신 안에서도 JVM을 돌려서 task를 수행한다.

##### Task Assignment
- 필요하다면, application Master는 모든 map과 reduce task의 container 정보를 resource manager에게 요청한다.
- map task가 reduce task 보다 우선 순위가 높다.
- reduce task는 어디서든 실행될 수 있지만, map task는 data locality에 따라서 scheduler가 노드를 할당한다.
##### Task Execution
- application Master가 node manager에 접근함으로서 container가 시작된다.
- 작업에 필요한 데이터를 local로 불러온다.
- 그 후에서야 task를 수행한다.

##### Progress and State Updates
- status
  - task's status
  - map과 reduce의 진행상황
  - job의 갯수를 counting한 값
  - 상태 메세지(user code에 대한)
- 각 각의 task들은 application Master와 정보를 주고 받는다.
- client는 매 초마다 application Master에게 polling을 보냄으로서 상태 정보를 받을 수 있다.
- map의 진행상황은 input을 처리한 정도를 의미한다.
- reduce의 경우에는 copy와 sort and reduce phase모두를 의미하며 이 각 단계가 차례차례 진행되며 reduce task의 진행 사항을 의미한다.

##### Job completion
- 모든 작업이 종료되면 application Master는 successful 상태로 바뀌고, <br>
resource Manager는 모든 container를 정리한다.


### Failures and Job scheduling
##### Task Failure
- failure가 발생하면, 이를 Application Master에 전송하고, application master는 이를 실패한 작업이라고 marking한 후, 해당 container를 해제한다.
- 중단 된 작업의 경우, Application Master는 진행률 업데이트를받지 못했다는 것을 확인하고 작업을 실패한 것으로 표시한다. → JVM 프로세스가 자동으로 종료됩니다.
- 이러한 실패가 보고되면, scheduling은 조정된다.
  - 일단 이전에 실패한 노드에게는 다시 할당하지 않는다.
  - 4번 이상 실패한다면, 다시는 이 task를 실행하지 않는다.
##### Application Master Failure
- application Master는 주기적으로 heartbeats를 resource Manager에게 보낸다.
- 만약, application Master가 실패한다면, resource Manager는 이를 감지하고 새로운 container에 새로운 master를 실행시킨다.
- 사실은 client에서 timeout을 감지하고, 이 시점에 새로운 Application Master를 요청하는 것이다.

##### Node Manager Failure
- 10분(default)동안 nodeManager로 부터 heartbeat가 없으면 resource Manager는 이를 알게된다.
- 이는 resourceManager에 의해서 복구된다.
- 응용 프로그램의 failure의 수가 높은 경우, 노드 관리자가 블랙리스트에 오른다.

##### Resource Manager Failure
- 어떤 작업도 수행될 수 없다.
- SPOF(Single point of Failure) =하나가 실패하면 모두 실패한다.
- 복구할 수 없는 위험이 발생한다.
- 따라서, High Availability를 보장할려면 resource Manager를 하나 이상 더 둔다.

### Shuffle and Sort
- reducer에 정렬된 키를 전달하는 것을 MapReduce는 보장해야 한다.
- 정렬과 이를 reducer에 전달하는 것까지는 shuffle이라고 한다.

##### Workflow
1. Map Task(split 하나 당 한 번)
  - input split이 들어와 이를 Map 함수에서 처리한다.
  - 처리한 데이터는 차곡차곡 memory에 있는 buffer에 쌓인다.
  - 해당 데이터가 일정 이상 쌓이면 disk에 쓰는 과정이 수행된다.
    - 이때 데이터들을 partitioning하여 조각낸다.
    - 그 후 동일한 key 값을 가진 대상끼리 묶어서 저장한다.
2. Reduce Task(key값 하나 당 한 번)
  - 먼저 map task에서 생성한 결과물들 중 원하는 데이터만을 copy하여 가져온다.(key단위로 불러옴)
  - 다른 node로 부터 데이터를 불러와서 이를 merge sorting하여 최종 reduce input을 만들어낸다.
  - 이를 reduce 함수를 통해 돌려서 output을 얻는다.

### Task Execution
- 만약, 작업의 속도가 느린 노드가 있다면, 해당 노드와 완전히 똑같은 작업을 다른 노드에서 실행시킨다.
- 일정 threashold를 넘지 않았을 때만, 이러한 과정을 수행한다.
