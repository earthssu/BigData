# Advanced Spark

### Caching
- partitioning되어 persist() or cache()한 데이터는 memory에 저장되어 이후의 반복작업 또는 이를 필요로하는 작업에서 훨씬 빠른 동작을 수행할 수 있게 한다. 또한, 이는 여러 군데에 replication 되어 fault tolerant를 보장한다.
- persist를 선언할 때, 여러가지 방식을 통해 데이터를 caching할 수 있다.
- 유의해서 볼 점
  - 저장 위치
    1. Disk
    2. Memory
    3. OffHeap
  - 직렬화 여부
    - 직렬화 시에는 더 많은 processing time이 발생하지만, memory 절약을 할 수 있다.
  - #replication

<img src="./img/persistMode.png">


| raw Caching                          | serialized Caching                 |
|--------------------------------------|------------------------------------|
| pretty fast to process               | slower processing than raw caching |
| can take up 2x - 4x more space       | overhead is minimal                |
| can put pressure in jvm and jvm G.C. | less pressure                      |

- cache의 삭제는 LRU Algorithm에 따라서 가장 덜 쓰인 순서대로 삭제된다.
- 직접 제거해주고 싶다면, unpersisit()를 사용하면된다.

### File Format
- MapReduce와 동일
- sc.textFile()로 여러 file format으로 저장할 수 있다.
- ex. csv txt json 등 등
- 저장할 때 역시 rdd.saveAsTextFile()로 어디든 저장할 수 있다.

### File Compression
- MapReduce와 동일
- gzip은 빠르고, 높은 효율성을 보여줘서 많이쓰인다.
- bzip2같은 경우는 압축 속도가 느리지만, 매우 효율적이여서 쓰이는 경우가 많다.

### File System
- hdfs든 s3든 일반적인 file system이든 여러 형태의 file system에 접근할 수 있다.
- file => file:///path
- hdfs => hdfs://master:port/path
- s3 => s3n://path (aws access/secret key 필요)
- json파일 같은 겨우 Hive를 이용한 spark SQL로 QUERY 수행도 가능하다.

### Accumulator
- Closure : code block밖에서도 이에 접근하여 사용할 수 있는 기능.(js, Rudy 등이 이를 지원한다.)
- 기본적으로 spark에서 이러한 closure는 작동하지 않는다.
- cluster환경에서 전역 변수가 넘쳐나서 좋을 것이 없기 때문이다.
- 하지만, 이를 어느정도는 지원하기 위해 만들어진것이 Accumulator이다.
- 해당 변수는 오직 added만 가능하다.(write-only)
