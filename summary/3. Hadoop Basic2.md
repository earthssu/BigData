# Hadoop Basic 2

- BigData를 하나의 node에 전속시키는 것은 부담이 크다. 따라서, 이를 partitioning하여 분리된 노드에 각 각 나눌 필요가 생겼다.
- 분산 파일 시스템의 등장이다.
- 이들은 network로 연결되고 network 성능에 많은 것이 좌우된다.

### HDFS
- Hadoop에서 사용하는 distributed file system이다.
- petabytes 넘어서까지 저장이 가능하다.
- write-once, read-many times pattern 일 경우 매우 효율적이다.
- 슈퍼 컴퓨터가 아닌 보통 성능의 pc를 엮어서 만들어지도록 설계되었다.


##### Trade-off
- High-latency
  - HDFS는 높은 효율로 데이터를 전달시키는 데에 최적화되어있다. 이를 위한 전처리과정이 발생하여 latency가 상승할 수 있다.
- Lots of small files
  - 백만의 파일까지는 가능하지만, 십억개는 현재로서는 불가능하다.
- Multiple writers, arbitrary file modifications
  - 파일의 내용 or 작성자에 대한 정보를 바꿀 때에는 효율이 매우 떨어진다.

##### Blocks
- 1.x에서는 block 사이즈를 64mb로 하였고, 2.x에서는 128mb로 이를 두 배 증가시켰다. <br>
storage system을 단순화할 수 있고 탐색 비용이 줄어든다.
- single disk에 담을 수 없는 정보도 담을 수 있다.
- storage subsystem을 단순화할 수 있다.
- 복사에 적합하여 fault tolerance와 availability를 확보할 수 있다.

##### Namenode
- hdfs에서는 하나의 master node와 다수의 worker nodes로 나뉜다.
- 이때 master node가 namenode이다.
- 해당 node는 filesystem의 namespace를 관리한다.
- 해당 namespace에는 모든 file과 directory들의 정보가 담긴 tree와 metadata를 포함한다.
- 특정 file에 모든 block이 어디에 존재하는지를 알고 있다.
- 따라서, namenode가 뻗어버리면, 해당 file이 어떻게 어디에 저장되었는지 알 방법이 없다.(SPOF)
- datanode가 갖고 있는 것은 모두 쓰레기가 된다.
- 이를 방지하기 위해 namenode는 실패에 매우 탄력있게 반응해야한다.<br>
  - 1. filesystem의 metat데이터에 지속적으로 상태를 back up해놓는다.
  - 2. secondary namenode를 가동시킨다.
  - (부가적으로 Hadoop 2.x에서는 두 개의 node를 두어 하나가 뻗었을 때, 바로 인계받아 수행할 수 있도록 구현하였다.)
##### Secondary Namenode
- 주기적으로 namespace의 이미지를 편집 기록과 합친다. 모든 변경사항을 저장하여 부피가 거치는 것을 방지한다.
- namenode와는 분리되어 구분되는 node에서 작동된다. <br>
namenode의 정보를 merge하는데에 많은 memory와 CPU가 필요하기 때문이다.

##### Datanode
- datanode들은 file system의 작업장이다.
- 그들이 불려질 때, block의 저장과 검색을 수행한다.
- 저장중인 block의 list를 주기적으로 namenode에게 알린다.

##### file write
1. client는 namenode에게 파일 저장을 요청한다.
2. client의 data를 data node에서 받고, 이를 다른 datanode에 복사하여 저장한다.
3. 복사본을 받는 노드는 다음 조건에 따라 저장합니다. <br>
같은 rack에 있는 노드 중에 하나, 인접 reg에 있는 노드 중 하나. 총 3개를 저장한다. <br>
이 방식은 fault tolerance(신뢰성)와 data locality(대역폭)를 보장하기 위해 고안되었다.
4. 복사받은 노드들은 ack를 보내고 이를 최종으로 namenode에게 전송하여 작업 종료와 위치를 알린다.


##### file Read
1. client는 fileSystem에게 open을 요청한다.
2. fileSystem에서는 namenode를 통해 해당 데이터가 어디에 위치하는지를 알아낸다.(이때 copy가 있는 모든 노드의 위치를 전송한다.)
3. 이 정보를 받은 client를 read 명령을 통해 데이터를 읽어온다.
4. read 명령을 받은 InputStream은 가장 가까운 datanode를 찾고 데이터를 받아온다.
5. 해당 노드가 읽는 것이 불가능한 경우 인접노드에게 요청한다. (이 과정에서 실패한 노드에 정보도 namenode에 checksum을 통해 전송한다.)
6. 마지막으로 client는 해당 inputStream을 종료한다.

추가적으로 mapreduce를 구현할 때는 데이터를 read하는 비용을 줄이기 위해서 data가 있는 노드에 task를 할당하는 locality에 알맞게 job을 할당한다.
