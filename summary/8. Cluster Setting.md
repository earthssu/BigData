# Cluster Setting

### Environment
- Ubuntu 16.04
- Hadoop-2.7.6
- JAVA 8
- SSH

### All Step
- 아래 모든 과정은 모든 node에서 동일하게 수행해주어야함.(master는 추가적인 사항이 있습니다.)

1. 모든 node의 사설 ip를 입력합니다.
```bash
$vi /etc/hosts
$vi /etc/hostname
  #statements
```
  - 127.0.0.1 localhost 위에 각 노드의 사설 ip와 이름을 부여 <br>
(ex. 192.168.0.35 [node명])
  - 이때, hosts에 자신의 이름도 꼭 추가하자.
  - hostname에서는 자신의 hostname을 다른 사람이 입력한 것과 동일하게 변경

2. 각 노드 간의 자유로운 접근을 위해 ssh key를 서로에게 넘겨줍니다.
```bash
$ssh-keygen -t rsa - P ""
$ssh-copy-id -i ~/.ssh/id_rsa/pub [node명]
```

3. hadoop 및 java의 환경변수가 제대로 입력되었는지 확인합니다.

4. hadoop-env.sh를 설정합니다.<br>
이 부분이 없다면 추가.
```
for f in $HADOOP_HOME/contrib/capacity-scheduler/*.jar; do
  if [ "$HADOOP_CLASSPATH" ]; then
    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$f
  else
    export HADOOP_CLASSPATH=$f
  fi
done
```

5. mapred-site.xml
```
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

6. core-site.xml
```
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://${master}:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/home/hadoop/hadoop-2.6.5/tmp</value>
  </property>
</configuration>
```

7. hdfs-site.xml
- master

```
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/home/hadoop/hadoop-2.6.5/data/namenode</value>
  </property>
</configuration>
```

- slave

```
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/home/hadoop/hadoop-2.6.5/data/datanode</value>
  </property>
</configuration>
```

8. yarn-site.xml

```
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>${master}</value>
  </property>
</configuration>
```

9. start
  - master만 수행한다.

```bash
$hadoop namenode -format
$./sbin/start-all.sh
$jps
$hdfs dfsadmin -report

$ssh master jps; ssh slave1 jps; ssh slave2 jps; ssh slave3 jps;
```
